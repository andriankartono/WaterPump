{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predictive Maintenance of Water Pump in Africa</h1>\n",
    "\n",
    "This project is about using data analysis to predict when a water pump will be non-functional. The Dataset comes from the drivendata.org. <br>\n",
    "To start this project we will like to import the data into our notebook and begin some basic analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (59400, 2))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_values = pd.read_csv(\"Training_Set_Values.csv\")\n",
    "df_labels = pd.read_csv(\"Training_set_labels.csv\")\n",
    "\n",
    "df_values.shape, df_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result above, there are 40 features and 59400 observations in the dataset. <br>\n",
    "The first feature is the ID Number of the pump, which we will ignore.<br> \n",
    "Out of the other 39 features, we will drop some features manually.<br>\n",
    "Possible reasons for drop are:<br>\n",
    "* Duplicates/Redundant Column\n",
    "* Feature assumed to have little to no correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 22)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df = df_values.drop(columns=[\"longitude\", \"latitude\", \"wpt_name\", \"num_private\",\n",
    "                              \"recorded_by\", \"permit\", \"payment\", \"payment_type\", \n",
    "                              \"waterpoint_type_group\", \"basin\", \"subvillage\", \n",
    "                              \"region\", \"source\", \"extraction_type_group\", \n",
    "                              \"extraction_type_class\", \"district_code\", \"quantity_group\", \"lga\", \"ward\"])\n",
    "\n",
    "#Include Status into the DF so that any mutations we do to the df is done to the Status Series as well.\n",
    "dropped_df[\"Status\"] = df_labels[\"status_group\"]\n",
    "dropped_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping some features, we are now left with 20 features. However not all of the observations have complete data and thus we will have to do some preprocessing to the new df. Some of the possible step we will take for the preprocessing are: <br>\n",
    "* Dropping Observations that are not able to be predicted and is considered important e.g. Population\n",
    "* Predicting Values that may seem possible to be predicted\n",
    "* Leaving the NaN Values as it is and use one hot encoder.<br>\n",
    "\n",
    "Columns that have string values such as funder, installer, extraction type, etcwill be encoded using one hot encoder.<br> For these Columns, we will not drop rows that has NaN Values to avoid losing too much data<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with population = 0\n",
    "dropped_df1= dropped_df[dropped_df[\"population\"] != 0]\n",
    "dropped_df1=pd.get_dummies(dropped_df1, columns=[\"funder\", \"installer\", \"public_meeting\", \n",
    "                                    \"scheme_management\", \"scheme_name\", \"extraction_type\", \n",
    "                                    \"management\", \"management_group\", \"water_quality\", \n",
    "                                    \"quality_group\", \"quantity\", \"source_type\", \n",
    "                                    \"source_class\", \"waterpoint_type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Using the pandas OneHotEncoder Method, we now have a dataset that looks ready for fitting into the model.<br>\n",
    "However, one of the feature that can be a problem is the date_recorded as it is not in a suitable data form for fitting.<br>\n",
    "The optimal way to work with a date time feature is to convert it to a np.datetime format which has lot of built-in methods and function to it.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Used to turn off the warning that occurs because of chained assignment\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "dropped_df1[\"date_recorded\"] =pd.to_datetime(dropped_df1[\"date_recorded\"])\n",
    "dropped_df1.dtypes[\"date_recorded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the date_recorded column is in np.datetime format, lets separate the year-month-date into separate columns that will <br>\n",
    "fitted into the classifier that we will be creating later. As the value of date may not be as important as month or year,<br>\n",
    "We will not be using the date value in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38019, 5044)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df1[\"year\"] = dropped_df1[\"date_recorded\"].dt.year\n",
    "dropped_df1[\"month\"] = dropped_df1[\"date_recorded\"].dt.month\n",
    "dropped_df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataframe is almost ready. We just need to drop the 3 unnecessary columns left which are:\n",
    "* id\n",
    "* date_recorded\n",
    "* Status (needs to be stored in a series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= dropped_df1[\"Status\"]\n",
    "data=dropped_df1.drop(columns=[\"date_recorded\", \"id\", \"Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data are ready to be fitted into the model,<br>\n",
    "We can begin thinking about the model that we will want to use.<br>\n",
    "<br>\n",
    "We will be starting by splitting the dataframe into train set and test set<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both training set and test set ready, we now have to make a decision on which model and hyperparameter to use.<br>\n",
    "We will use 3 types of model with a small parameter grid to check each model accuracy.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNeighborsClassifier</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10960/3164149453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;34m\"clf__n_neighbors\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m }\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mKNN_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNN_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKNN_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1_micro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mKNN_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'score'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "KNN_pipe= Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
    "KNN_grid= {\n",
    "    \"clf__n_neighbors\" : np.arange(5,15,2)\n",
    "}\n",
    "KNN_clf = GridSearchCV(KNN_pipe, KNN_grid, n_jobs=3, cv=3, scoring=\"f1_micro\")\n",
    "KNN_clf.fit(x_train,y_train)\n",
    "\n",
    "print(classification_report(y_test, KNN_clf.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LogisticRegression</h1>\n",
    "\n",
    "Next LogisticRegression classifier. The LogisticRegression Classifier is basically a classifier that uses a linear boundary.<br>\n",
    "The important things to note here is since there are more than 2 possible result (non-binary classifier), the classifier will use a one vs rest implementation \n",
    "instead of a 0.5 probability threshold<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Logres_pipe= Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])\n",
    "Logres_grid= {\n",
    "    \"clf__C\" : np.logspace(0.1,1000, num=5)\n",
    "}\n",
    "Logres_clf = GridSearchCV(Logres_pipe, Logres_grid, n_jobs=3, cv=3, scoring=\"f1_micro\")\n",
    "Logres_clf.fit(x_train,y_train)\n",
    "\n",
    "print(classification_report(y_test, Logres_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Logres_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logres_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logres_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logres_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTC_pipe= Pipeline([('scaler', StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "DTC_grid= {\n",
    "    \"clf__max_features\" : [\"auto\", \"sqrt\", \"log2\"]\n",
    "}\n",
    "DTC_clf = GridSearchCV(DTC_pipe, DTC_grid, n_jobs=3, cv=3, scoring=\"f1_micro\")\n",
    "DTC_clf.fit(x_train,y_train)\n",
    "\n",
    "print(classification_report(y_test, DTC_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Visualization </h2>\n",
    "\n",
    "First let us prepare some useful lists that will most probably be used multiple times in the future<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all the classifier model to a list for future use\n",
    "model_list= [KNN_clf,Logres_clf,DTC_clf]\n",
    "model_name_list = [\"kNearestNeighbors\", \"Logistic Regression\", \"Decision Tree Classifier\"]\n",
    "score_list=[]\n",
    "label_list=[\"functional\", \"functional needs repair\",\"non functional\"]\n",
    "\n",
    "for model in model_list:\n",
    "    score_list.append(round(model.best_score_,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us compare the scores of the classifier models side by side using a bar chart.<br>\n",
    "We will be using the plotly module for visualization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig1= px.bar(y=model_name_list, x=score_list, hover_name=score_list)\n",
    "fig1.update_layout(title_text=\"Classifier Accuracy\", title_x=0.5)\n",
    "fig1.update_xaxes(title_text=\"Accuracy Score\")\n",
    "fig1.update_yaxes(title_text=\"Classification Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, these are the accuracy score of each model. We would then also visualize a confusionmatrix<br>\n",
    "which will allows us to compare prediction probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf1=confusion_matrix(y_test, KNN_clf.predict(x_test), normalize=\"true\", labels=label_list)\n",
    "cf2=confusion_matrix(y_test, Logres_clf.predict(x_test), normalize=\"true\", labels=label_list)\n",
    "cf3=confusion_matrix(y_test, DTC_clf.predict(x_test), normalize=\"true\", labels=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 =go.Figure()\n",
    "for cf in [cf1,cf2,cf3]:\n",
    "    fig2.add_trace(go.Heatmap(\n",
    "        x=label_list,y=label_list,z=cf, hoverinfo=\"text\", hovertext=np.round(cf,5)\n",
    "    ))\n",
    "dropdown_buttons = [  \n",
    "    {'label': 'KNN', 'method': 'update','args': [{'visible': [True, False, False]}, {'title': 'KNearestNeighbors classification Matrix'}]},  \n",
    "    {'label': 'LogisticRegression', 'method': 'update','args': [{'visible': [False, True, False]}, {'title': 'LogisticRegression classification Matrix'}]},  \n",
    "    {'label': \"DecisionTreeClassifier\", 'method': \"update\",'args': [{\"visible\": [False, False, True]}, {'title': 'DecisionTreeClassifier classification Matrix'}]}\n",
    "    ]\n",
    "\n",
    "fig2.update_layout(title_text=\"KNearestNeighbors classification Matrix\")\n",
    "fig2.data[1].visible=False\n",
    "fig2.data[2].visible=False\n",
    "fig2.update_layout(updatemenus=[{'type': \"dropdown\",'x': 1.25,'y': 0.5,'showactive': True,'active': 0,'buttons': dropdown_buttons}], title_x=0.5)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f895f3828335fe46f73ce365c88adfdf701549b1031659c6fc3c92d79d692c8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
